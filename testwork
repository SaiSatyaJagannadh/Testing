from datetime import datetime  # ADD THIS LINE


import json
import zipfile
import pandas as pd
from pathlib import Path
import logging
from config import INPUT_DIR, UPLOADS_DIR

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class FileReader:
    def __init__(self):
        self.knowledge_data = []
        self.load_knowledge_base()
    
    def load_knowledge_base(self):
        """Load existing knowledge from input folder - READ ALL FILES"""
        try:
            logger.info(f"Loading knowledge base from: {INPUT_DIR}")
            
            # List all files in input directory
            all_files = list(INPUT_DIR.glob('*'))
            logger.info(f"Found {len(all_files)} files in input directory")
            
            for file_path in all_files:
                logger.info(f"Processing file: {file_path.name}")
                
                if file_path.suffix.lower() in ['.xlsx', '.csv']:
                    logger.info(f"Reading Excel file: {file_path.name}")
                    excel_data = self._read_excel(file_path)
                    self.knowledge_data.extend(excel_data)
                    logger.info(f"Added {len(excel_data)} entries from {file_path.name}")
                    
                elif file_path.suffix.lower() == '.zip':
                    logger.info(f"Reading ZIP file: {file_path.name}")
                    zip_data = self._read_zip(file_path)
                    self.knowledge_data.extend(zip_data)
                    logger.info(f"Added {len(zip_data)} entries from {file_path.name}")
                    
                elif file_path.suffix.lower() == '.json':
                    logger.info(f"Reading JSON file: {file_path.name}")
                    json_data = self._read_json(file_path)
                    self.knowledge_data.extend(json_data)
                    logger.info(f"Added {len(json_data)} entries from {file_path.name}")
                    
                else:
                    logger.info(f"Skipping unsupported file: {file_path.name}")
            
            logger.info(f"✓ TOTAL KNOWLEDGE LOADED: {len(self.knowledge_data)} entries from all files")
            
            # Debug: Show what was loaded
            if self.knowledge_data:
                logger.info("Sample loaded data:")
                for i, entry in enumerate(self.knowledge_data[:3]):
                    logger.info(f"  Entry {i+1}: {entry}")
            
        except Exception as e:
            logger.error(f"Error loading knowledge base: {str(e)}")
    
    def read_uploaded_file(self, file_path):
        """Read newly uploaded file"""
        file_path = Path(file_path)
        logger.info(f"Reading uploaded file: {file_path.name}")
        
        if file_path.suffix.lower() in ['.txt', '.log']:
            return self._read_log_file(file_path)
        elif file_path.suffix.lower() == '.json':
            return self._read_json(file_path)
        elif file_path.suffix.lower() in ['.xlsx', '.csv']:
            return self._read_excel(file_path)
        elif file_path.suffix.lower() == '.zip':
            return self._read_zip(file_path)
        else:
            raise ValueError(f"Unsupported file format: {file_path.suffix}")
    
    def _read_log_file(self, file_path):
        """Read text/log files"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            lines = content.split('\n')
            log_data = {
                'filename': file_path.name,
                'content': content,
                'lines': lines,
                'total_lines': len(lines)
            }
            return [log_data]
        except Exception as e:
            logger.error(f"Error reading log file {file_path}: {str(e)}")
            return []
    
    def _read_excel(self, file_path):
        """Read Excel/CSV files - IMPROVED"""
        try:
            logger.info(f"Reading Excel file: {file_path}")
            
            if file_path.suffix.lower() == '.csv':
                df = pd.read_csv(file_path)
            else:
                df = pd.read_excel(file_path)
            
            logger.info(f"Excel file has {len(df)} rows and columns: {list(df.columns)}")
            
            # Convert to standard format - TRY DIFFERENT COLUMN NAMES
            data = []
            for _, row in df.iterrows():
                # Try different possible column names
                jobname = (row.get('jobname') or row.get('job_name') or 
                          row.get('Job Name') or row.get('JobName') or '')
                
                error = (row.get('error') or row.get('errors') or 
                        row.get('Error') or row.get('Errors') or 
                        row.get('error_message') or row.get('ErrorMessage') or '')
                
                solution = (row.get('solution') or row.get('solutions') or 
                           row.get('Solution') or row.get('Solutions') or 
                           row.get('resolution') or row.get('Resolution') or '')
                
                entry = {
                    'jobname': str(jobname),
                    'error': str(error),
                    'solution': str(solution),
                    'source': file_path.name
                }
                
                # Only add if we have both error and solution
                if entry['error'] and entry['solution'] and entry['error'] != 'nan' and entry['solution'] != 'nan':
                    data.append(entry)
            
            logger.info(f"✓ Extracted {len(data)} valid entries from Excel file")
            return data
            
        except Exception as e:
            logger.error(f"Error reading Excel file {file_path}: {str(e)}")
            return []
    
    def _read_json(self, file_path):
        """Read JSON files"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # Normalize JSON structure
            if isinstance(data, list):
                return data
            elif isinstance(data, dict):
                return [data]
            return []
        except Exception as e:
            logger.error(f"Error reading JSON file {file_path}: {str(e)}")
            return []
    
    def _read_zip(self, file_path):
        """Read ZIP files and extract text files"""
        try:
            extracted_data = []
            with zipfile.ZipFile(file_path, 'r') as zip_ref:
                for file_info in zip_ref.filelist:
                    if file_info.filename.endswith(('.txt', '.log')):
                        content = zip_ref.read(file_info.filename).decode('utf-8')
                        log_data = {
                            'filename': file_info.filename,
                            'content': content,
                            'lines': content.split('\n'),
                            'source_zip': file_path.name
                        }
                        extracted_data.append(log_data)
            return extracted_data
        except Exception as e:
            logger.error(f"Error reading ZIP file {file_path}: {str(e)}")
            return []
    
    def get_knowledge_base(self):
        """Return loaded knowledge base"""
        return self.knowledge_data

# Test the reader
if __name__ == "__main__":
    reader = FileReader()
    print(f"Knowledge base loaded: {len(reader.get_knowledge_base())} entries")
    
    # Show what was loaded
    kb = reader.get_knowledge_base()
    for i, entry in enumerate(kb[:5]):
        print(f"Entry {i+1}: {entry}")
